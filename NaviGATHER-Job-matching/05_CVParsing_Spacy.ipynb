{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355d8c66-5f29-4c11-a81f-e0c2ef3c80c8",
   "metadata": {},
   "source": [
    "# SPACY\n",
    "\n",
    "https://spacy.io/usage\n",
    "\n",
    "Install:\n",
    "\n",
    "`conda install -c conda-forge spacy`\n",
    "\n",
    "`python -m spacy download en_core_web_sm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f6b7a-f0fd-40e0-9509-719b270543da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e514e1db-0cb9-469f-b77c-d4b316e4ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 'rainy'\n",
    "w2 = 'sunny'\n",
    "\n",
    "w1 = nlp.vocab[w1]\n",
    "w2 = nlp.vocab[w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53cfb1ef-cbdd-46fe-8de9-dea74d0214e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7039623260498047"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a088930-a3c7-4283-8e13-d2d0ea0f368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = nlp(\"I belive in the god and the bible\")\n",
    "s2 = nlp(\"I trust in a higher power of Christianity\")\n",
    "s3 = nlp(\"This weekend John will drink a beer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09461e44-b05a-4757-8313-81bb86869a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8592989444732666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.similarity(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a71d78d0-77fe-4816-8bbc-1e516f0506d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70660001039505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.similarity(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f0f35-cf59-4e79-81d7-3cdbfc4ffacb",
   "metadata": {},
   "source": [
    "## Using verb or adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c420e89-d668-4058-8366-2c9f269e41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = nlp('I play football in this awful arena.')\n",
    "s2 = nlp('I play the piano in this red room.')\n",
    "s3 = nlp('I repair the piano in this ugly room.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8346efc-52e3-4ab0-a630-7e812c5ee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_verbs = \" \".join([token.lemma_ for token in s1 if token.pos_ == \"VERB\"])\n",
    "s1_nouns = \" \".join([token.lemma_ for token in s1 if token.pos_ == \"NOUN\"])\n",
    "s1_adjs = \" \".join([token.lemma_ for token in s1 if token.pos_ == \"ADJ\"])\n",
    "\n",
    "s2_verbs = \" \".join([token.lemma_ for token in s2 if token.pos_ == \"VERB\"])\n",
    "s2_nouns = \" \".join([token.lemma_ for token in s2 if token.pos_ == \"NOUN\"])\n",
    "s2_adjs = \" \".join([token.lemma_ for token in s2 if token.pos_ == \"ADJ\"])\n",
    "\n",
    "s3_verbs = \" \".join([token.lemma_ for token in s3 if token.pos_ == \"VERB\"])\n",
    "s3_nouns = \" \".join([token.lemma_ for token in s3 if token.pos_ == \"NOUN\"])\n",
    "s3_adjs = \" \".join([token.lemma_ for token in s3 if token.pos_ == \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "036d1954-237f-4010-a35d-fff895539aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I play football in this awful arena.and I play the piano in this red room. VERBS: 1.0\n",
      "I play football in this awful arena.and I repair the piano in this ugly room. VERBS: 0.16859392821788788\n"
     ]
    }
   ],
   "source": [
    "print(f'{s1}and {s2} VERBS: {nlp(s1_verbs).similarity(nlp(s2_verbs))}')\n",
    "print(f'{s1}and {s3} VERBS: {nlp(s1_verbs).similarity(nlp(s3_verbs))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c606e-b2df-478f-9c7e-6f612e444d8f",
   "metadata": {},
   "source": [
    "## Match the whole text for example skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8961d218-3edd-4c7d-b6b4-2753b7b1e8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "#import pandas as pd \n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy \n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from tika import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad27dd-6d04-408d-92d6-be5efda47866",
   "metadata": {},
   "source": [
    "### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "326069b2-08d4-4c3d-8bd3-366543c58d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdffile):\n",
    "    \"\"\"Read PDF file ans=d parse as text\"\"\"\n",
    "    pdf = PyPDF2.PdfReader(pdffile)\n",
    "    text = \"\"\n",
    "\n",
    "    for i in range(len(pdf.pages)):\n",
    "        pageObj = pdf.pages[i]\n",
    "        text += pageObj.extract_text()\n",
    "    return text\n",
    "\n",
    "def preprocess(text):\n",
    "  text = \"\".join([s for s in text.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "  # text = re.sub('[^A-Za-z0-9\\n]+', ' ', text)\n",
    "  return text\n",
    "\n",
    "sub_directory_for_resume = 'CV'\n",
    "files_list_resume = os.listdir('CV')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b726f7a-049d-401b-a122-d281eebeb829",
   "metadata": {},
   "source": [
    "### Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48373541-c45b-4fd2-bec2-27e52a851e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jd_file(filename):\n",
    "    \"\"\"Program to read the entire file (absolute path) using read() function\"\"\"\n",
    "    file = open(filename, \"r\")\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    return content\n",
    "\n",
    "sub_directory_for_jd = 'JD'\n",
    "files_list_jd = os.listdir('JD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d2a7fef-195d-4fde-bcf3-36a16e82130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_file_paths = [os.path.join(sub_directory_for_resume, file) for file in files_list_resume]\n",
    "resume = pdf_to_text(resume_file_paths[0])\n",
    "resume = preprocess(text)\n",
    "\n",
    "jd_file_paths = [os.path.join(sub_directory_for_jd, file) for file in files_list_jd]\n",
    "jd_text = read_jd_file(jd_file_paths[1])\n",
    "jd_text = preprocess(jd_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee573d35-3b38-49b8-82d7-a245b301699d",
   "metadata": {},
   "source": [
    "### Load Model for NER\n",
    "\n",
    "This model has to be fine tune using GPU training again with resume/jobdescription dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0cdb713-5ae6-43cc-acd1-fe0411fabf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ce0ec-9515-4d6a-9ec2-4d385220f305",
   "metadata": {},
   "source": [
    "### Extract NER labels from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba86bb24-b5a3-45d5-99c7-8695749b62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(text, nlp):\n",
    "    '''This function get the conntent of resume and label them '''\n",
    "    ner_labels = []\n",
    "    for doc in nlp.pipe([text], disable=[\"tagger\", \"parser\"]):\n",
    "      for ent in doc.ents:\n",
    "          text_name = re.sub('[^A-Za-z0-9]+', ' ', ent.text).strip()\n",
    "          ner_labels.append((text_name, ent.label_))\n",
    "    return ner_labels\n",
    "\n",
    "ner_labels_resume = extract_ner(resume, nlp)\n",
    "ner_labels_jd = extract_ner(jd_text, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43340097-ab25-4ed8-affc-af72a6bda964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"EXPERIENCE\": [\n",
      "    \"6 years of experience as Oracle Pl Sql D eveloper and have experience in creating complex database objects like Stored Procedures Functions Packages and Triggers using SQL and\"\n",
      "  ],\n",
      "  \"TOOL\": [\n",
      "    \"PL SQL\",\n",
      "    \"Associative arrays\",\n",
      "    \"Nested tables\",\n",
      "    \"Varrays\",\n",
      "    \"Cursors\",\n",
      "    \"SQL\",\n",
      "    \"PL SQL\",\n",
      "    \"DBMS JOB\",\n",
      "    \"UTL FILE\",\n",
      "    \"SQL\",\n",
      "    \"PL SQL\",\n",
      "    \"HINTS\",\n",
      "    \"Oracle\",\n",
      "    \"Export\",\n",
      "    \"EXPDP\",\n",
      "    \"OLTP\",\n",
      "    \"OLAP\",\n",
      "    \"SQL\",\n",
      "    \"PL SQL\",\n",
      "    \"T SQL\",\n",
      "    \"UNIX Shell Script\",\n",
      "    \"HTML\",\n",
      "    \"PHP Java\",\n",
      "    \"Oracle 11g 12C\",\n",
      "    \"MS SQL SERVER\",\n",
      "    \"TOAD\",\n",
      "    \"SQL Developer\",\n",
      "    \"ADDM\",\n",
      "    \"AWR\",\n",
      "    \"Github\",\n",
      "    \"Windows XP 10\",\n",
      "    \"Linux\",\n",
      "    \"Oracle PL SQL Developer Project Smartdata\",\n",
      "    \"PL SQL\",\n",
      "    \"sql\",\n",
      "    \"SQL Loader\",\n",
      "    \"UNIX scripts\",\n",
      "    \"Oracle database tables\",\n",
      "    \"Oracle Data Pump\",\n",
      "    \"Oracle database\",\n",
      "    \"PL SQL\",\n",
      "    \"BitBucket\",\n",
      "    \"JIRA\",\n",
      "    \"Confluence\",\n",
      "    \"SourceTree\",\n",
      "    \"Bamboo\",\n",
      "    \"PL SQL scripts\",\n",
      "    \"Oracle12c\",\n",
      "    \"TOAD\",\n",
      "    \"SQL Developer\",\n",
      "    \"MSExcel\",\n",
      "    \"Github\",\n",
      "    \"Jenkins\",\n",
      "    \"UNIX\",\n",
      "    \"Oracle PL SQL Developer\",\n",
      "    \"Connect Risk Engine Genesis\",\n",
      "    \"PL SQL stored procedures\",\n",
      "    \"SQL\",\n",
      "    \"PL SQL engines\",\n",
      "    \"FLAT\",\n",
      "    \"CSV\",\n",
      "    \"Oracle 11g\",\n",
      "    \"SQL\",\n",
      "    \"TOAD\",\n",
      "    \"SQL DEVELOPER\",\n",
      "    \"XML\",\n",
      "    \"Shell script\",\n",
      "    \"MS Access\",\n",
      "    \"GIT\",\n",
      "    \"UNIX\",\n",
      "    \"Oracle PL SQL\",\n",
      "    \"Oracle SQL\",\n",
      "    \"PL\",\n",
      "    \"TYPE\",\n",
      "    \"REF cursors\",\n",
      "    \"Visio\",\n",
      "    \"SQL\",\n",
      "    \"UNIX scr ipts\",\n",
      "    \"Shell Scripts\",\n",
      "    \"SQL script\",\n",
      "    \"PL SQL Script\",\n",
      "    \"PL SQL Functions\",\n",
      "    \"PL SQL code\",\n",
      "    \"mainframe systems\",\n",
      "    \"oracle database\",\n",
      "    \"Shell scripting\",\n",
      "    \"Unix Shell Scripts\",\n",
      "    \"Oracle 11g\",\n",
      "    \"Reports 10g\",\n",
      "    \"Oracle PL SQL\",\n",
      "    \"DML\",\n",
      "    \"SQL\",\n",
      "    \"Bitmap\",\n",
      "    \"UTL FILE\",\n",
      "    \"DMBS SQL\",\n",
      "    \"PL SQL Collections\",\n",
      "    \"Oracle 11G\",\n",
      "    \"SQL Developer\",\n",
      "    \"SQL Plus\",\n",
      "    \"UNIX Shell Scripts\"\n",
      "  ],\n",
      "  \"SKILL\": [\n",
      "    \"Data flow diagrams\",\n",
      "    \"Database normalization theory techniques\",\n",
      "    \"design techniques\",\n",
      "    \"Tables Views Constraints Index\",\n",
      "    \"B Tree\",\n",
      "    \"Logical and Physical Data Modeling using Normalization Techniques\",\n",
      "    \"Analytical skills\"\n",
      "  ],\n",
      "  \"ORG\": [\n",
      "    \"Chicago State University Chicago IL\",\n",
      "    \"Masterc ard O Fallon\",\n",
      "    \"Mphasis Corporation\",\n",
      "    \"CNA financial Corp Chicago IL\"\n",
      "  ],\n",
      "  \"DEGREE\": [\n",
      "    \"Master of Science Computer Science\",\n",
      "    \"Bachelors of Technology Electrical and Electronics Engineering\"\n",
      "  ],\n",
      "  \"EDUC\": [\n",
      "    \"JNTU Hyderabad Telangana\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def to_json(ner_labels):\n",
    "    # Create a defaultdict to group items by label\n",
    "    grouped_data = defaultdict(list)\n",
    "    \n",
    "    # Group the items by their labels\n",
    "    for item, label in ner_labels:\n",
    "        grouped_data[label].append(item)\n",
    "    \n",
    "    # Convert the defaultdict to a regular dictionary\n",
    "    json_data = dict(grouped_data)\n",
    "    \n",
    "    # Convert the dictionary to a JSON string\n",
    "    json_string = json.dumps(json_data, indent=2)\n",
    "    return json_string\n",
    "\n",
    "resume_json = to_json(ner_labels_resume)\n",
    "print(resume_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbf150b6-cf0f-4749-bb6e-55605d940d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"TOOL\": [\n",
      "    \"Oracle DBA\",\n",
      "    \"Oracle EBS\",\n",
      "    \"AP FA GL and Coupa\",\n",
      "    \"Oracle database\",\n",
      "    \"EBS R12 2 x objects\",\n",
      "    \"Oracle team\",\n",
      "    \"Oracle SRS\",\n",
      "    \"SQL\",\n",
      "    \"Pl sql\",\n",
      "    \"Putty\",\n",
      "    \"WinSCP\",\n",
      "    \"Joms\"\n",
      "  ],\n",
      "  \"EXPERIENCE\": [\n",
      "    \"6 months\",\n",
      "    \"Previous banking knowledge\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "jd_json = to_json(ner_labels_jd)\n",
    "print(jd_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81b0d918-ba68-44f7-8f32-6ab76937b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(ner_results, label):\n",
    "    '''This function extracts skills from NER results\n",
    "    label can be SKILL, EXPERIENCE, TOOL ...'''\n",
    "    \n",
    "    results = [item[0] for item in ner_results if item[1] == label]\n",
    "    return results\n",
    "\n",
    "# Extract from jd\n",
    "skills_jd = extract_skills(ner_labels_jd, 'SKILL')\n",
    "experience_jd = extract_skills(ner_labels_jd, 'EXPERIENCE')\n",
    "tool_jd = extract_skills(ner_labels_jd, 'TOOL')\n",
    "\n",
    "# Extract from resume\n",
    "skills_cv = extract_skills(ner_labels_resume, 'SKILL')\n",
    "experience_cv = extract_skills(ner_labels_resume, 'EXPERIENCE')\n",
    "tool_cv = extract_skills(ner_labels_resume, 'TOOL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87ff4c26-afb5-47d6-8e2e-8af1535e883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score \n",
      ": Skill: 0.0 \t Tool: 0.0 \t Experience: 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_score(cv_subset, jd_subset):\n",
    "    #  join the skills in each list into a single string\n",
    "    resume_text = ' '.join(cv_subset)\n",
    "    jd_text = ' '.join(jd_subset)\n",
    "    \n",
    "    #create Doc objects for each\n",
    "    doc_resume = nlp(resume_text)\n",
    "    doc_jd = nlp(jd_text)\n",
    "    \n",
    "    #compute the similarity\n",
    "    similarity_score = doc_resume.similarity(doc_jd)\n",
    "    return similarity_score\n",
    "\n",
    "skill_score = get_score(skills_cv, skills_jd)\n",
    "tool_score = get_score(tool_cv, tool_jd)\n",
    "exp_score = get_score(experience_cv, experience_jd)\n",
    "\n",
    "print(f\"Similarity score \\n: Skill: {skill_score} \\t Tool: {tool_score} \\t Experience: {exp_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "097f796c-3f58-427f-b872-36d9b01959b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_skills_1 = \"\"\"Business Requirements Analysis, Systems Design, Prototype Development, Impact Analysis, Design Specifications Creation\"\"\"\n",
    "test_skills = \"\"\"Possess the ability to assess business requirements, perform impact analysis against the existing system and provide analysis on integrating business change.\n",
    "Demonstrated ability to create Design Specifications based on System Use Cases, User Stories, Business Use Cases, and/or Requirements Documents.\n",
    "Translate business requirements into systems design and technical specifications.\n",
    "Work with developers to model and produce functional prototype and an operational system including all forms, manuals programs, data files and procedures.\n",
    "Provide expert consultation in production system analysis, performance, scalability security and maintenance.\n",
    "Define input/output sources including a detailed plan for technical design phase.\n",
    "Participates in sprint and cycle planning with the agile team.\n",
    "Validates proposed solution for alignment to business needs, requirements, and impacts to operations, processes, technology, vendors, partners and clients.\"\"\"\n",
    "\n",
    "print(get_score(test_skills_1, test_skills))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3e426f0-a93e-4b4f-b0ee-36eca74eaf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
