{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355d8c66-5f29-4c11-a81f-e0c2ef3c80c8",
   "metadata": {},
   "source": [
    "# SPACY\n",
    "\n",
    "Load JD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c606e-b2df-478f-9c7e-6f612e444d8f",
   "metadata": {},
   "source": [
    "## Match the whole text for example skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8961d218-3edd-4c7d-b6b4-2753b7b1e8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "#import pandas as pd \n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy \n",
    "from spacy.scorer import Scorer\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training.example import Example\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from tika import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326069b2-08d4-4c3d-8bd3-366543c58d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jd_file(filename):\n",
    "    \"\"\"Program to read the entire file (absolute path) using read() function\"\"\"\n",
    "    file = open(filename, \"r\")\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    return content\n",
    "\n",
    "def preprocess(text):\n",
    "  text = \"\".join([s for s in text.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "  # text = re.sub('[^A-Za-z0-9\\n]+', ' ', text)\n",
    "  return text\n",
    "\n",
    "sub_directory_for_jd = 'JD'\n",
    "files_list = os.listdir('JD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2a7fef-195d-4fde-bcf3-36a16e82130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_file_paths = [os.path.join(sub_directory_for_jd, file) for file in files_list]\n",
    "complete_file_paths\n",
    "\n",
    "jd_text = read_jd_file(complete_file_paths[1])\n",
    "jd_text = preprocess(jd_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee573d35-3b38-49b8-82d7-a245b301699d",
   "metadata": {},
   "source": [
    "### Load Model for NER\n",
    "\n",
    "This model has to be fine tune using GPU training again with resume/jobdescription dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0cdb713-5ae6-43cc-acd1-fe0411fabf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ce0ec-9515-4d6a-9ec2-4d385220f305",
   "metadata": {},
   "source": [
    "### Extract NER labels from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba86bb24-b5a3-45d5-99c7-8695749b62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(text, nlp):\n",
    "    '''This function get the conntent of resume and label them '''\n",
    "    ner_labels = []\n",
    "    for doc in nlp.pipe([text], disable=[\"tagger\", \"parser\"]):\n",
    "      for ent in doc.ents:\n",
    "          text_name = re.sub('[^A-Za-z0-9]+', ' ', ent.text).strip()\n",
    "          ner_labels.append((text_name, ent.label_))\n",
    "    return ner_labels\n",
    "\n",
    "ner_labels = extract_ner(jd_text, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43340097-ab25-4ed8-affc-af72a6bda964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"TOOL\": [\n",
      "    \"Oracle DBA\",\n",
      "    \"Oracle EBS\",\n",
      "    \"AP FA GL and Coupa\",\n",
      "    \"Oracle database\",\n",
      "    \"EBS R12 2 x objects\",\n",
      "    \"Oracle team\",\n",
      "    \"Oracle SRS\",\n",
      "    \"SQL\",\n",
      "    \"Pl sql\",\n",
      "    \"Putty\",\n",
      "    \"WinSCP\",\n",
      "    \"Joms\"\n",
      "  ],\n",
      "  \"EXPERIENCE\": [\n",
      "    \"6 months\",\n",
      "    \"Previous banking knowledge\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def resume_json(ner_labels):\n",
    "    # Create a defaultdict to group items by label\n",
    "    grouped_data = defaultdict(list)\n",
    "    \n",
    "    # Group the items by their labels\n",
    "    for item, label in ner_labels:\n",
    "        grouped_data[label].append(item)\n",
    "    \n",
    "    # Convert the defaultdict to a regular dictionary\n",
    "    json_data = dict(grouped_data)\n",
    "    \n",
    "    # Convert the dictionary to a JSON string\n",
    "    json_string = json.dumps(json_data, indent=2)\n",
    "    return json_string\n",
    "\n",
    "jd_json = resume_json(ner_labels)\n",
    "print(jd_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81b0d918-ba68-44f7-8f32-6ab76937b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oracle DBA', 'Oracle EBS', 'AP FA GL and Coupa', 'Oracle database', 'EBS R12 2 x objects', 'Oracle team', 'Oracle SRS', 'SQL', 'Pl sql', 'Putty', 'WinSCP', 'Joms']\n"
     ]
    }
   ],
   "source": [
    "def extract_skills(ner_results, label):\n",
    "    '''This function extracts skills from NER results\n",
    "    label can be SKILL, EXPERIENCE, TOOL ...'''\n",
    "    \n",
    "    results = [item[0] for item in ner_results if item[1] == label]\n",
    "    return results\n",
    "\n",
    "# Extract skills\n",
    "skills_jd = extract_skills(ner_labels, 'SKILL')\n",
    "experience_jd = extract_skills(ner_labels, 'EXPERIENCE')\n",
    "tool_jd = extract_skills(ner_labels, 'TOOL')\n",
    "\n",
    "print(tool_jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba40ee-e6f9-4efd-b37c-65124b96f743",
   "metadata": {},
   "source": [
    "## CHECK file from spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892d1fb4-e0fa-4ab2-b43b-7e088a2b35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "  nlp = spacy.load('./model')\n",
    "  return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d161e3f3-1198-44c7-8e60-bab3a7d1ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_number):\n",
    "  '''Loads text data of training data which is in annotated form. Enter file_number between 0 to 50 '''\n",
    "  spider_tagged_data = 'spider_software_tagged_data'\n",
    "  list_tagged_files = os.listdir(spider_tagged_data)\n",
    "  file_path = os.path.join(spider_tagged_data,list_tagged_files[file_number])\n",
    "  with open(file_path,'r') as f:\n",
    "    data = json.load(f)\n",
    "  return data['annotations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "780cb118-dac9-4f6b-b84e-7771a2490677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://stackoverflow.com/questions/68213223/how-to-evaluate-trained-spacy-version-3-model#:~:text=nlp%20%3D%20spacy.load(path_to_model)%0Aexamples%20%3D%20%5B%5D%0Ascorer%20%3D%20Scorer()%0Afor%20text%2C%20annotations%20in%20TEST_REVISION_DATA%3A%0A%20%20%20%20doc%20%3D%20nlp.make_doc(text)%0A%20%20%20%20example%20%3D%20Example.from_dict(doc%2C%20annotations)%0A%20%20%20%20example.predicted%20%3D%20nlp(str(example.predicted))%0A%20%20%20%20examples.append(example)%0Ascorer.score(examples)\n",
    "def score_metrics(nlp,data):\n",
    "  examples = []\n",
    "  scorer = Scorer()\n",
    "  for text, annotations in data:\n",
    "      doc = nlp.make_doc(text)\n",
    "      example = Example.from_dict(doc, annotations)\n",
    "      example.predicted = nlp(str(example.predicted))\n",
    "      examples.append(example)\n",
    "  result_metrics = scorer.score(examples)\n",
    "  return result_metrics['ents_per_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3466ef35-286d-4571-b97c-70680c59eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(file_number):\n",
    "    '''In this function it takes file number as input and correspondingly choose required annotated file from the folder.And after that it can \n",
    "    show the output of precision,recall,f1_score\n",
    "    '''\n",
    "    data = load_json_file(file_number)\n",
    "    print('The data looks like:')\n",
    "    print('='*100)\n",
    "    for a in data:\n",
    "        print(a)\n",
    "    nlp = load_model()\n",
    "    \n",
    "    result_net = score_metrics(nlp,data)\n",
    "    print('='*100)\n",
    "    print('The result metrics are down below')\n",
    "    print('-'*100)\n",
    "    for i,j in result_net.items():\n",
    "       print(i,' ',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ca0cd16-156e-48bd-9012-573896d806c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data looks like:\n",
      "====================================================================================================\n",
      "['Network Engineer Network Admin Resume', {'entities': [[0, 16, 'JOB_TITLE'], [17, 30, 'JOB_TITLE']]}]\n",
      "['Job Level Experienced with over 2 years experience', {'entities': [[10, 50, 'EXPERIENCE']]}]\n",
      "['Objective SUMMARYAn IT professional with over 10 years of experience in engineering administration implementation network monitoring and management analysis escalation support documentation configuration and troubleshooting for medium to global enterprise environments which includes proficiency in routing routing protocols switching security voice wireless data center technologies and firewall management ', {'entities': [[20, 83, 'EXPERIENCE'], [84, 407, 'EXPERIENCE']]}]\n",
      "['Experience Spydaweb LLC Consultant 2013 Present Responsibilities include management of various teams to facilitate the creation of new Consumer product invention Management of vendor relationships and triage of associated technology challenges were a key part of this role Managed Product design and engineering for manufacture with team of Industrial Engineers and Product Concept Designers Professional tasks included but not limited to validating networking skill sets Transunion LLC Senior Enterprise Support Analyst 2006 2013Company Overview Transunion LLC is a worldwide company that provides credit information and information management services to approximately 45 000 businesses and approximately 500 million consumers in 33 countries It is the 3rd largest credit bureau in the United States Responsibilities handled Member to a team responsible for 2nd and 3rd tier client technical support scripting administration monitoring network support and troubleshooting for various LAN WAN network infrastructures which included heterogeneous system environments Technologies handled by the team include but not limited to local area network LAN technologies wide area network WAN technologies server and enterprise applications and desktop technologies Specific technologies were Linux Unix windows and Mainframe platforms SQL XPATH database querying bash scripting and Python program code modification Professional responsibilities included administration mentor training documentation following policies and procedures and scheduling as needed reports to management Sprint Nextel Communications Inc Information Security Analyst 2000 2005Company Overview Sprint Nextel provides wireless services and it is a major global internet carrier mobile service provider Responsibilities handled Lead Change Coordinator to a team of professionals responsible for 1st and 2nd tier support client vendor relationships change management understanding of internet protocols implementation configuration validation maintenance and troubleshoot activities on various LAN WAN firewall infrastructures Technologies handled by the team include but not limited to Checkpoint firewall rule base changes PIX firewall later replaced by ASAs and training client on networking concepts Specific responsibilities were command line utilities such as tcpdump netstat windows and an understanding of various Internet protocols and on the GUI side apps such as Checkpoint NGX Suite of products Policy Editor Log View were used and Etherpeek Wireshark for troubleshooting Professional responsibilities included administration training documentation following corporate policies and procedures and as the Change Coordinator representing the firewall changes during Management meetings Vanstar Inacom Company Tier 2 Escalation Support HHD FT 1998 2000Company Overview Vanstar Inacom Company was a large national seller of PC s and services At one point it was the third largest and most profitable computer distributor in the United States Responsibilities handled Member to a team of professionals responsible for supporting field technicians vendor hardware installation configuration and troubleshooting of various enterprise infrastructures for hardware issues Specific technologies handled by the team include but not limited to LAN WAN technologies and end user PCs HP IBM Compaq Apple Mac Servers HP IBM SUN printers HP Canon Xerox Epson Kyocera and POS DEC Compaq Contractor IHD 1998 1998Company Overview Compaq Computer Corporation was a company who sold and supported computers related products and services in the US and the UK In 2000 they merged with HP this is their largest facility Responsibilities handled Member to a team of professionals responsible for level 1 phone support of the IT infrastructure to include resolving connectivity issues onsite administration and support scheduled installation configuration and troubleshoot activities which included software Technologies handled by the team include but not limited to wide area network WAN technologies desktop technologies and dialer software Professional responsibilities included administration following corporate policies and procedures documentation and a weekly statistics report ', {'entities': [[11, 34, 'ORG'], [40, 151, 'EXPERIENCE'], [162, 196, 'EXPERIENCE'], [281, 295, 'SKILL'], [450, 460, 'SKILL'], [472, 504, 'ORG'], [927, 973, 'SKILL'], [986, 1017, 'TOOL'], [1285, 1303, 'TOOL'], [1308, 1346, 'TOOL'], [1356, 1370, 'TOOL'], [1375, 1389, 'TOOL'], [1447, 1477, 'EXPERIENCE'], [1478, 1572, 'EXPERIENCE'], [1573, 1601, 'ORG'], [2189, 2201, 'TOOL'], [2220, 2224, 'TOOL'], [2330, 2353, 'TOOL'], [2416, 2419, 'TOOL'], [2449, 2452, 'TOOL'], [2508, 2527, 'TOOL'], [2760, 2782, 'ORG'], [2842, 2864, 'ORG'], [3349, 3352, 'ORG'], [3360, 3365, 'ORG'], [3398, 3400, 'ORG']]}]\n",
      "['Education Certified WAN Professional Program LANWAN ProfessionalElectrical Electronics Engineering Chattanooga State', {'entities': [[10, 116, 'EXPERIENCE']]}]\n",
      "['Affiliations CCNP Certified current CCNA Certified current ', {'entities': [[13, 58, 'EXPERIENCE']]}]\n",
      "['Skills Routing Switching Technologies Cisco Routers 3900 2900 1900 800 Series Cisco Catalyst Switch 6500 5500 4900 4500 3750 3560 X 3100 Cisco Nexus 1kv 2k 5k 7K Series Juniper and HP Routers Switches WAN LAN TCP IP Cisco IOS Spanning Tree Protocol BPDU CDP ACL NAT PAT RIP RIPv2 OSPF OSPFv6 EIGRP BGP MPLS VTP SNMP SMTP ARP TCP UDP Static Routing Stub Routing VLAN VLAN Trunking VXLANs Multicast routing HSRP SVI CEF Etherchannel Portfast VSS VPC Security Firewalls Technologies Cisco Security Manager Suite Cisco ASA 5500 series firewalls Cisco FWSM Cisco IPS IDS Cisco ACS Palo Alto Advanced Firewall Manager AFM Cisco ASA 1000V cloud firewall Juniper SRX series Protocols Standards AAA TACACS RADIUS SSH VPN IPSec SSL IPSec Data Loss Prevention Data Management Zone Pretty Good Protection PGP Public Key Infrastructure PKI Internet Key Exchange Policy Port Security MAC Address FilteringData Center Technologies VMware VSphere VCenter Server Appliance VMware ESXi Hypervisor F5 Big IP load balancing GTM LTM Cisco AnyConnect VPN mtg Riverbed WAN Opt device management Cisco IPS IDS Meraki cloud based Wireless Technologies Cisco WLC Aironet Bluetooth CUCM UCCM UCCX Avaya AURA Communication Manager Avaya Definity Avaya IP Office Voice Technologies Voice Over Internet Protocol VoIP VoIP SIP MGCP RTP SCCP SRTP Quality of Service QoS PoE IEEE 802 1x 802 11 WLAN WAP AP SSID LWAPP CSMA CA MMDS LMDS CCK DSSSMonitoring APPS Wireshark Remedy Cacti Nagios VMware Solarwinds Cisco Security Manager Suite Server Sniffer Ethereal Orion SNMPv2c SNMPv3 DNS DHCP FTP Telnet HTTP S SMTP tunneling protocols PTP SFTP RDP Other Technologies Microsoft windows Apple MacOS X Linux Mainframe SQL Oracle CRM CMS HTML CSS Scripting Adobe Creative Suite ', {'entities': [[7, 1738, 'SKILL']]}]\n",
      "====================================================================================================\n",
      "The result metrics are down below\n",
      "----------------------------------------------------------------------------------------------------\n",
      "JOB_TITLE   {'p': 1.0, 'r': 1.0, 'f': 1.0}\n",
      "EXPERIENCE   {'p': 0.8888888888888888, 'r': 0.8888888888888888, 'f': 0.8888888888888888}\n",
      "ORG   {'p': 1.0, 'r': 1.0, 'f': 1.0}\n",
      "SKILL   {'p': 1.0, 'r': 1.0, 'f': 1.0}\n",
      "TOOL   {'p': 1.0, 'r': 1.0, 'f': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Here you can choose any number between 0 to 50 including both of them\n",
    "function_2(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
